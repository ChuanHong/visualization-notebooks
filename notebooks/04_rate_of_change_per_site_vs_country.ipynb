{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-reload frequently changed files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from altair_saver import save\n",
    "from os.path import join\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "from web import for_website\n",
    "\n",
    "from constants import COLUMNS, DATA_AGGREGATE_TYPES\n",
    "from utils import (\n",
    "    read_combined_daily_counts_df, read_combined_by_country_daily_counts_df, read_combined_by_site_daily_counts_df,\n",
    "    apply_theme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Common info that should be defined everytime before rendering visualizations\n",
    "\"\"\"\n",
    "SITES = read_combined_by_site_daily_counts_df()[COLUMNS.SITE_ID].unique()\n",
    "\n",
    "# Titles\n",
    "NUM_SITES = len(SITES)\n",
    "DATA_DATE = \"2020-04-10\"\n",
    "VIS_DATE = \"2020-04-10\"\n",
    "SUBTITLE = f\"Data as of {DATA_DATE} | {NUM_SITES} Sites | Plots generated on {VIS_DATE}\"\n",
    "\n",
    "SAVE_DIR = join(\"..\", \"output\") # Where to save visualization *.PNG files\n",
    "\n",
    "# Colors\n",
    "COMBINED = \"All countries\"\n",
    "COMBINED_COLOR = \"#444444\"\n",
    "\n",
    "COUNTRIES = [\"France\", \"Germany\", \"Italy\", \"Singapore\", \"USA\"]\n",
    "COUNTRY_COLOR = [\"#0072B2\", \"#E69F00\", \"#009E73\", \"#CC79A7\", \"#D55E00\"]\n",
    "COLOR_BY_COUNTRY = {COUNTRIES[i]: COUNTRY_COLOR[i] for i in range(len(COUNTRIES))} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = \"category\"\n",
    "\n",
    "def preprocess_daily_df(df_dc):\n",
    "\n",
    "    # Wide to long\n",
    "    df_dc = pd.melt(df_dc, id_vars=[\n",
    "        COLUMNS.SITE_ID, COLUMNS.DATE,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_DEATHS,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.UNMASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_DEATHS,\n",
    "        COLUMNS.MASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_SITES_NEW_DEATHS\n",
    "    ])\n",
    "    df_dc = df_dc.rename(columns={\"variable\": CATEGORY, \"value\": COLUMNS.NUM_PATIENTS})\n",
    "\n",
    "    # Leave only the 'upper' and 'under' values for the certain 'category' only\n",
    "    for c in [COLUMNS.NEW_POSITIVE_CASES, COLUMNS.PATIENTS_IN_ICU, COLUMNS.NEW_DEATHS]:\n",
    "        filter_c = df_dc[CATEGORY] == c\n",
    "        df_dc.loc[filter_c, \"upper\"] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] + df_dc.loc[filter_c, \"masked_upper_bound_\" + c]\n",
    "        df_dc.loc[filter_c, \"under\"] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS]\n",
    "        df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] = df_dc.loc[filter_c, COLUMNS.NUM_PATIENTS] + df_dc.loc[filter_c, \"masked_upper_bound_\" + c] / 2.0\n",
    "        \n",
    "        # Add num of sites\n",
    "        df_dc.loc[filter_c, COLUMNS.NUM_SITES] = df_dc[\"unmasked_sites_\" + c] + df_dc[\"masked_sites_\" + c]\n",
    "\n",
    "    # Drop unused columns\n",
    "    df_dc = df_dc.drop(columns=[\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_UPPER_BOUND_NEW_DEATHS,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.UNMASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.UNMASKED_SITES_NEW_DEATHS,\n",
    "        COLUMNS.MASKED_SITES_NEW_POSITIVE_CASES,\n",
    "        COLUMNS.MASKED_SITES_PATIENTS_IN_ICU,\n",
    "        COLUMNS.MASKED_SITES_NEW_DEATHS\n",
    "    ])\n",
    "    \n",
    "    return df_dc\n",
    "\n",
    "# Read files\n",
    "df_dc = preprocess_daily_df(read_combined_by_country_daily_counts_df())\n",
    "df_dc_site = preprocess_daily_df(read_combined_by_site_daily_counts_df())\n",
    "\n",
    "# Remove zero num_sites\n",
    "df_dc = df_dc[df_dc[COLUMNS.NUM_SITES] != 0]\n",
    "\n",
    "df_dc\n",
    "df_dc_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_category = \"new_positive_cases\"\n",
    "\n",
    "df_dc = df_dc.loc[df_dc[\"category\"] == for_category]\n",
    "df_dc = df_dc.rename(columns={\"siteid\": \"country\", \"num_patients\": \"count\"})\n",
    "\n",
    "unique_countries = df_dc[\"country\"].unique().tolist()\n",
    "df_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date_str):\n",
    "    try:\n",
    "        return dateutil.parser.parse(date_str)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# countries have different ids in the JHU data than in ours\n",
    "country_map = {\n",
    "    \"US\": \"USA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "jhu_df = pd.read_csv(jhu_url)\n",
    "\n",
    "jhu_df = jhu_df.rename(columns={\"Country/Region\": \"country\", \"Province/State\": \"state\"})\n",
    "jhu_df = jhu_df.drop(columns=[\"Lat\", \"Long\"])\n",
    "\n",
    "jhu_df[\"country\"] = jhu_df[\"country\"].apply(lambda c: country_map[c] if c in country_map else c)\n",
    "jhu_df = jhu_df.loc[jhu_df[\"country\"].isin(unique_countries)]\n",
    "jhu_df = jhu_df.loc[~pd.notna(jhu_df[\"state\"])]\n",
    "jhu_df = jhu_df.drop(columns=[\"state\"])\n",
    "\n",
    "jhu_df = jhu_df.melt(id_vars=[\"country\"], var_name=\"date\", value_name=\"cumulative_count\")\n",
    "\n",
    "jhu_df[\"date\"] = jhu_df[\"date\"].astype(str)\n",
    "jhu_df[\"date\"] = jhu_df[\"date\"].apply(convert_date)\n",
    "df_dc = df_dc.sort_values(by=\"date\", ascending=True)\n",
    "\n",
    "jhu_roc_df = pd.DataFrame(index=[], data=[], columns=[\"country\", \"date\", \"cumulative_count\", \"diff\", \"gradient\"])\n",
    "for country, country_df in jhu_df.groupby(\"country\"):\n",
    "    country_df = country_df.copy()\n",
    "    country_df[\"change\"] = np.concatenate((np.array([np.nan]), np.diff(country_df[\"cumulative_count\"].values)))\n",
    "    country_df[\"gradient\"] = np.gradient(country_df[\"cumulative_count\"].values)\n",
    "    country_df[\"cumulative_count\"] = country_df[\"cumulative_count\"].replace(0, np.nan)\n",
    "    \n",
    "    country_df[\"change\"] = country_df[\"change\"] / country_df[\"cumulative_count\"].max()\n",
    "\n",
    "    jhu_roc_df = jhu_roc_df.append(country_df, ignore_index=True)\n",
    "jhu_roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dc = df_dc.loc[df_dc[\"category\"] == for_category]\n",
    "df_dc[\"date\"] = df_dc[\"date\"].astype(str)\n",
    "df_dc[\"date\"] = df_dc[\"date\"].apply(convert_date)\n",
    "df_dc = df_dc.sort_values(by=\"date\", ascending=True)\n",
    "\n",
    "\n",
    "dc_roc_df = pd.DataFrame(index=[], data=[], columns=[\"country\", \"date\", \"count\", \"diff\", \"gradient\"])\n",
    "for country, country_df in df_dc.groupby(\"country\"):\n",
    "    country_df = country_df.copy()\n",
    "    country_df[\"cumulative_count\"] = np.cumsum(country_df[\"count\"].values)\n",
    "    country_df[\"cumulative_count\"] = country_df[\"cumulative_count\"].replace(0, np.nan)\n",
    "    \n",
    "    country_df[\"cumulative_upper\"] = np.cumsum(country_df[\"upper\"].values)\n",
    "    country_df[\"cumulative_upper\"] = country_df[\"cumulative_upper\"].replace(0, np.nan)\n",
    "    \n",
    "    country_df[\"cumulative_under\"] = np.cumsum(country_df[\"under\"].values)\n",
    "    country_df[\"cumulative_under\"] = country_df[\"cumulative_under\"].replace(0, np.nan)\n",
    "    \n",
    "    \n",
    "    cumulative_count_max = country_df[\"cumulative_count\"].max()\n",
    "    \n",
    "    country_df[\"change\"] = country_df[\"count\"] / cumulative_count_max\n",
    "    \n",
    "    country_df[\"change_upper\"] = country_df[\"upper\"] / cumulative_count_max\n",
    "    country_df[\"change_under\"] = country_df[\"under\"] / cumulative_count_max\n",
    "    \n",
    "\n",
    "    dc_roc_df = dc_roc_df.append(country_df, ignore_index=True)\n",
    "dc_roc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = datetime.datetime(2020, 1, 20)\n",
    "max_date = max(dc_roc_df[\"date\"].max(), jhu_roc_df[\"date\"].max())\n",
    "\n",
    "dc_roc_df = dc_roc_df.loc[dc_roc_df[\"date\"] >= min_date]\n",
    "jhu_roc_df = jhu_roc_df.loc[jhu_roc_df[\"date\"] >= min_date]\n",
    "\n",
    "country_selection = alt.selection_multi(fields=[\"country\"], bind=\"legend\")\n",
    "country = alt.condition(country_selection, alt.Color(\"country:N\"), alt.value(\"#EAEAEA\"))\n",
    "\n",
    "date_domain = [alt.DateTime(year=min_date.year, month=min_date.month, date=min_date.day), alt.DateTime(year=max_date.year, month=max_date.month, date=max_date.day)]\n",
    "date_scale = alt.X(\"date:T\", scale=alt.Scale(domain=date_domain))\n",
    "\n",
    "pct_domain = [0.0, 0.22]\n",
    "count_domain = [1, 1000000]\n",
    "\n",
    "plot = (\n",
    "    (\n",
    "        (\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_line()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"change:Q\", scale=alt.Scale(domain=pct_domain)),\n",
    "                    color=country\n",
    "                )\n",
    "                .properties(title=\"Rate of Change per Country (4CE)\")\n",
    "            +\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_errorband()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"change_upper:Q\", scale=alt.Scale(domain=pct_domain)), \n",
    "                    y2=\"change_under:Q\",\n",
    "                    color=country\n",
    "                )\n",
    "        ).resolve_scale(y=\"shared\").interactive()\n",
    "    | \n",
    "        (\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_line()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"cumulative_count:Q\", scale=alt.Scale(type=\"log\", domain=count_domain)),\n",
    "                    color=country\n",
    "                )\n",
    "                .properties(title=\"Country Cumulative Counts (4CE)\")\n",
    "            +\n",
    "            alt.Chart(dc_roc_df)\n",
    "                .mark_errorband()\n",
    "                .encode(\n",
    "                    x=date_scale,\n",
    "                    y=alt.Y(\"cumulative_upper:Q\", scale=alt.Scale(type=\"log\", domain=count_domain)), \n",
    "                    y2=\"cumulative_under:Q\",\n",
    "                    color=country\n",
    "                )\n",
    "        ).resolve_scale(color=\"shared\", y=\"shared\", x=\"shared\")\n",
    "    ) & (\n",
    "    alt.Chart(jhu_roc_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=date_scale,\n",
    "            y=alt.Y(\"change:Q\", scale=alt.Scale(domain=pct_domain)),\n",
    "            color=country\n",
    "        )\n",
    "        .properties(title=\"Rate of Change per Country (JHU)\")\n",
    "     | alt.Chart(jhu_roc_df)\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=date_scale,\n",
    "            y=alt.Y(\"cumulative_count:Q\", scale=alt.Scale(type=\"log\", domain=count_domain)),\n",
    "            color=country\n",
    "        )\n",
    "        .properties(title=\"Country Cumulative Counts (JHU)\")\n",
    "    )\n",
    ").add_selection(\n",
    "    country_selection\n",
    ")\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:c19i2b2-py] *",
   "language": "python",
   "name": "conda-env-c19i2b2-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
